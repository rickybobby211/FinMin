# RunPod Serverless Deployment Guide - Step by Step

## üìã Prerequisites

- Docker installerat (lokalt eller p√• RunPod)
- Docker Hub konto (gratis)
- RunPod konto med Serverless access
- HuggingFace token (f√∂r att ladda upp modellen)

---

## üöÄ Step 1: Upload Model to HuggingFace (Recommended)

Detta g√∂r modellen tillg√§nglig √∂verallt och enklare att anv√§nda.

### 1.1 Logga in p√• HuggingFace

```bash
# P√• RunPod pod (eller lokalt)
huggingface-cli login --token YOUR_HF_TOKEN
```

### 1.2 Skapa ett nytt repository p√• HuggingFace

1. G√• till: https://huggingface.co/new
2. V√§lj "Model"
3. Namn: `your-username/fingpt-v3-float16` (eller valfritt namn)
4. V√§lj "Private" eller "Public"
5. Klicka "Create repository"

### 1.3 Ladda upp modellen

```bash
# P√• RunPod pod
cd /runpod-volume/fingpt-v3-float16_202512060944

# Ladda upp till HuggingFace
huggingface-cli upload your-username/fingpt-v3-float16 ./ --repo-type model
```

**Eller om du vill g√∂ra det fr√•n din lokala dator:**

```bash
# Ladda ner modellen fr√•n RunPod volume f√∂rst (via SSH/scp)
# Sedan lokalt:
huggingface-cli login
huggingface-cli upload your-username/fingpt-v3-float16 ./fingpt-v3-float16_202512060944 --repo-type model
```

---

## üê≥ Step 2: Build Docker Image

### 2.1 Klona/√ñppna projektet lokalt

```bash
# Om du inte redan har det lokalt
git clone https://github.com/rickybobby211/FinMin.git
cd FinMin/fingpt/FinGPT_Forecaster/serverless
```

### 2.2 Bygg Docker-imagen

```bash
# Bygg imagen
docker build -t fingpt-forecaster:latest .

# Testa lokalt (valfritt)
docker run -it --rm \
  -e HF_TOKEN="your_token" \
  -e FINNHUB_API_KEY="your_key" \
  -e ADAPTER_PATH="your-username/fingpt-v3-float16" \
  fingpt-forecaster:latest
```

### 2.3 Tagga f√∂r Docker Hub

```bash
# Ers√§tt 'yourusername' med ditt Docker Hub anv√§ndarnamn
docker tag fingpt-forecaster:latest yourusername/fingpt-forecaster:latest
```

### 2.4 Logga in p√• Docker Hub

```bash
docker login
# Ange ditt Docker Hub username och password
```

### 2.5 Pusha till Docker Hub

```bash
docker push yourusername/fingpt-forecaster:latest
```

**Detta kan ta 5-10 minuter beroende p√• din internetanslutning.**

---

## ‚òÅÔ∏è Step 3: Create RunPod Serverless Endpoint

### 3.1 G√• till RunPod Dashboard

1. Logga in p√•: https://www.runpod.io/
2. G√• till **"Serverless"** i menyn
3. Klicka **"New Endpoint"**

### 3.2 Konfigurera Endpoint

**Basic Settings:**
- **Name**: `fingpt-forecaster-v3` (eller valfritt namn)
- **Container Image**: `yourusername/fingpt-forecaster:latest`
- **Container Disk**: `20 GB` (r√§cker f√∂r modellen)

**GPU Settings:**
- **GPU Type**: V√§lj baserat p√• behov:
  - `RTX 3090` - Bra balans (24GB VRAM)
  - `RTX 4090` - Snabbare (24GB VRAM)
  - `A100` - Snabbast men dyrare (40GB VRAM)

**Environment Variables:**
Klicka p√• **"Environment Variables"** och l√§gg till:

```
HF_TOKEN = hf_your_huggingface_token_here
FINNHUB_API_KEY = your_finnhub_api_key_here
ADAPTER_PATH = your-username/fingpt-v3-float16
```

**Viktigt:** 
- Om du laddade upp till HuggingFace: Anv√§nd `your-username/fingpt-v3-float16`
- Om du vill anv√§nda officiell FinGPT: L√§mna `ADAPTER_PATH` tom eller s√§tt till `FinGPT/fingpt-forecaster_dow30_llama2-7b_lora`

**Advanced Settings:**
- **Max Workers**: `1` (f√∂r att undvika VRAM-problem)
- **Flashboot**: `Enabled` (snabbare cold start)
- **Idle Timeout**: `5 minutes` (eller l√§ngre om du vill)

### 3.3 Skapa Endpoint

Klicka **"Create Endpoint"** och v√§nta p√• att den skapas (1-2 minuter).

---

## üß™ Step 4: Test Your API

### 4.1 H√§mta API Endpoint URL

Efter att endpointen √§r skapad:
1. Klicka p√• din endpoint
2. Kopiera **"Endpoint URL"** (ser ut som: `https://api.runpod.ai/v2/xxxxx`)

### 4.2 H√§mta API Key

1. G√• till: https://www.runpod.io/console/user/settings
2. Kopiera din **"API Key"**

### 4.3 Testa med curl

```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_RUNPOD_API_KEY" \
  -d '{
    "input": {
      "ticker": "AAPL",
      "date": "2025-12-06",
      "n_weeks": 3
    }
  }'
```

### 4.4 Testa med Python

```python
import requests

response = requests.post(
    "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run",
    headers={
        "Content-Type": "application/json",
        "Authorization": "Bearer YOUR_RUNPOD_API_KEY"
    },
    json={
        "input": {
            "ticker": "AAPL",
            "date": "2025-12-06",
            "n_weeks": 3
        }
    }
)

print(response.json())
```

### 4.5 Testa med Web UI

Om du har `web_ui.py`:

```bash
export RUNPOD_API_URL="https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run"
export RUNPOD_API_KEY="your_runpod_api_key"
python web_ui.py
```

√ñppna `http://localhost:5000` i webbl√§saren.

---

## üîß Troubleshooting

### Problem: "Model not found"
**L√∂sning:** Kontrollera att `ADAPTER_PATH` √§r korrekt i environment variables.

### Problem: "Out of memory"
**L√∂sning:** 
- Anv√§nd st√∂rre GPU (A100)
- Eller minska `max_new_tokens` i `handler.py`

### Problem: "Cold start timeout"
**L√∂sning:** 
- √ñka timeout i RunPod settings
- Eller anv√§nd "Flashboot" f√∂r snabbare startup

### Problem: "API returns error"
**L√∂sning:** 
- Kolla logs i RunPod dashboard
- Verifiera att alla environment variables √§r satta

---

## üí∞ Cost Estimation

**RunPod Serverless Pricing:**
- RTX 3090: ~$0.00029/sekund (~$1.04/timme) n√§r aktiv
- RTX 4090: ~$0.00039/sekund (~$1.40/timme) n√§r aktiv
- A100: ~$0.00069/sekund (~$2.48/timme) n√§r aktiv

**Typisk request:**
- Cold start: ~30-60 sekunder (laddar modellen f√∂rsta g√•ngen)
- Warm request: ~10-20 sekunder (modellen redan laddad)

**Kostnad per request:**
- Cold: ~$0.01-0.02
- Warm: ~$0.003-0.006

---

## üìö Next Steps

1. **Monitor Usage:** Kolla RunPod dashboard f√∂r anv√§ndning och kostnader
2. **Optimize:** Justera `max_new_tokens` f√∂r snabbare svar
3. **Scale:** L√§gg till fler workers om du har h√∂g trafik
4. **Integrate:** Anv√§nd API:et i dina applikationer

---

## ‚úÖ Checklist

- [ ] Modell uppladdad till HuggingFace
- [ ] Docker image byggd och pushad till Docker Hub
- [ ] RunPod Serverless endpoint skapad
- [ ] Environment variables konfigurerade
- [ ] API testat och fungerar
- [ ] Web UI fungerar (valfritt)

**Grattis! Din FinGPT modell √§r nu live p√• RunPod Serverless! üéâ**

